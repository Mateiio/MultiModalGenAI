munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/../pers/matei/repos/MultiModalGenAI$ git config  user.email "matei.p.iordanescu@gmail.com"
munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/../pers/matei/repos/MultiModalGenAI$ git config  user.name "matei iordanescu"

munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/../pers/matei/repos$ /usr/local/cuda/bin/nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Wed_Aug_14_10:10:22_PDT_2024
Cuda compilation tools, release 12.6, V12.6.68
Build cuda_12.6.r12.6/compiler.34714021_0

munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/../pers/matei/repos$ cat /usr/local/cuda/version.json

C:\crtUsers\..\pers\matei\repos\MultiModalGenAI>nvidia-smi.exe
Sun Oct 13 20:33:27 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 561.09                 Driver Version: 561.09         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+

munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/[..]/pers/matei/repos$ dpkg --print-architecture
amd64
__________________________________________________________________________________________

https://www.python.org/downloads/
Python version Maintenance status First released End of support Release schedule
3.13 bugfix 2024-10-07 2029-10 PEP 719
3.12 bugfix 2023-10-02 2028-10 PEP 693

C:\crtUsers\..\pers\matei\repos>git clone https://github.com/Mateiio/MultiModalGenAI.git
Cloning into 'MultiModalGenAI'...
remote: Enumerating objects: 5, done.
remote: Counting objects: 100% (5/5), done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (5/5), done.


https://github.com/microsoft/Phi-3CookBook
https://azure.microsoft.com/en-us/blog/new-models-added-to-the-phi-3-family-available-on-microsoft-azure/
https://medium.com/@researchgraph/what-is-phi-3-5-vision-101ce7c4d410
#https://github.com/pytorch/pytorch/blob/main/Dockerfile
https://hub.docker.com/r/huggingface/transformers-pytorch-gpu/dockerfile
https://hub.docker.com/r/huggingface/transformers-pytorch-gpu/




https://discuss.huggingface.co/t/need-example-docker-file-with-gpu-support/57747/3
https://huggingface.co/spaces/SpacesExamples/llama-cpp-python-cuda-gradio/blob/main/Dockerfile
https://github.com/ollama/ollama/blob/main/Dockerfile

https://huggingface.co/spaces/SpacesExamples/Gradio-Docker-Template-nvidia-cuda/blob/main/Dockerfile
https://hub.docker.com/r/nvidia/cuda/tags
#FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04
FROM nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04


munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/[..]/pers/matei/repos/MultiModalGenAI/docker$ cd /mnt/c/crtUsers/[..]/pers/matei/repos/MultiModalGenAI/docker
munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/[..]/pers/matei/repos/MultiModalGenAI/docker$ docker build -t mmgenai .

cd ./../../
munix@DESKTOP-FQLOSI3:/mnt/c/crtUsers/[..]/pers/matei/repos$
docker run \
-it \
--rm \
--gpus all \
--name mmgenaicntnr \
-p 8890:8888 \
-v $(pwd):/workspace:rw \
mmgenai \
/bin/bash -c "jupyter lab --notebook-dir=/ --ip='*' --port=8888 --no-browser --allow-root"

