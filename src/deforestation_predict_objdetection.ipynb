{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826db936-5c2e-4ac7-a7c6-ffaf53e4d09b",
   "metadata": {},
   "source": [
    "# Deforestation quantification using classification based object detection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910981eb-dc83-407a-9a14-befd1dae4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c0918-371f-47ea-b2a9-ac5a7617fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# https://github.com/tensorflow/tensorflow/issues/65419\n",
    "# import tf_keras\n",
    "version_fn = getattr(tf.keras, \"version\", None)\n",
    "if version_fn and version_fn().startswith(\"3.\"):\n",
    "    import tf_keras as keras\n",
    "else:\n",
    "    keras = tf.keras\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f226b-f04b-433e-a8ea-8bf0f1e1203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b11f1-e11f-4b04-9955-074e2b50c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc2e1f-33f2-4880-8332-3092b5f46e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = './../../Data/MultiModalGenAI/resisc45/NWPU-RESISC45_small'\n",
    "output_models_dir = './../../models/MultiModalGenAI/deforestation'\n",
    "# modelfname= 'deforestation_model_1736702508'#'deforestation_model_1735604427' \n",
    "modelfname= 'deforestation_model_1736723402'\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ba3bd-da10-4733-a2c4-9103988be537",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model(f'{output_models_dir}/{modelfname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec041e31-80a7-4a0c-9bd1-f30d175a7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = pathlib.Path(input_data_dir).with_suffix('')\n",
    "image_count = len(list(dataset_path.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9c25e-2011-450d-b69d-0de0b8b5788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(dataset_path),\n",
    "  validation_split=.997,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e44d3-188f-43a5-85c7-b7e202d1063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(test_ds.class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f95e67-9247-4599-9202-0fe673ae222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca958623-586c-4d1a-96a9-3b4ba0a37322",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b4aba-8662-4a1c-ad61-e9d85b338a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_image_batch, test_labels_batch in test_ds:\n",
    "  print(test_image_batch.shape)\n",
    "  print(test_image_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cb45a-0a7f-4ad1-acc8-be35dbd092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(class_names[test_labels_batch], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3aa784-f9e6-4d17-94b5-bff149b007f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_batch = trained_model.predict(test_image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c1ef2-485a-40f8-9648-51c7dbdf7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_id = tf.math.argmax(test_predictions_batch, axis=-1)\n",
    "test_predicted_label_batch = class_names[test_predicted_id]\n",
    "print(test_predicted_label_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223a9ec-6582-4ee5-a5f6-6233ec71b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,12))\n",
    "_ = plt.subplots_adjust(wspace=.5, hspace=0.5)\n",
    "for n in range(15):\n",
    "    _ = plt.subplot(3,5,n+1)\n",
    "    _ = plt.imshow(test_image_batch[n])\n",
    "    _ = plt.title(f'Pred:{str(test_predicted_label_batch[n].title())}\\nReal:{class_names[test_labels_batch[n]]}')\n",
    "    _ = plt.axis('off')\n",
    "    _ = plt.suptitle(\"Model predictions on Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e7961-8fb6-451e-a71e-458fed39913c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c3e807-5964-402d-96bc-7723a2b6eea1",
   "metadata": {},
   "source": [
    "## Patched Object Detection using transfer learning based image classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f706d38-5d0d-41b0-b1ac-0c40b60206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_patches = lambda x: (tf.reshape(\n",
    "    tf.image.extract_patches(\n",
    "        images=tf.expand_dims(x, 0),\n",
    "        sizes=[1, patch_height, patch_width, 1],\n",
    "        strides=[1, stride_height, stride_width, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'), (-1, patch_height, patch_width, 3))\n",
    ")\n",
    "\n",
    "def create_heatmap(predicts_ids, patches_order, patches_shape):\n",
    "    patch_num_y, patch_num_x = patches_order\n",
    "    patch_height, patch_width = patches_shape\n",
    "    # heatmap = np.full(patches_shape, np.nan)\n",
    "    index = 0\n",
    "    heatmap = np.full(patches_shape, predicts_ids[index])\n",
    "    index+=1\n",
    "    \n",
    "    for col_index in range(patch_num_x-1):\n",
    "        heatmap = np.concatenate((heatmap,np.full(patches_shape, predicts_ids[index])),axis=1)\n",
    "        index+=1\n",
    "        \n",
    "    for row_index in range(patch_num_y-1):\n",
    "        rowarray  = np.full(patches_shape, predicts_ids[index])\n",
    "        index+=1\n",
    "        for col_index in range(patch_num_x-1):\n",
    "            rowarray = np.concatenate((rowarray,np.full(patches_shape, predicts_ids[index])),axis=1)\n",
    "            index+=1\n",
    "        heatmap = np.concatenate((heatmap, rowarray),axis=0)\n",
    "        \n",
    "    return heatmap\n",
    "\n",
    "# https://keras.io/examples/vision/grad_cam/\n",
    "def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    # jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image, cropped to match the heatmap\n",
    "    superimposed_img = jet_heatmap * alpha + img[:heatmap.shape[0],:heatmap.shape[1],:]\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    return  tf.keras.utils.load_img(cam_path)\n",
    "\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(img_height, img_width),\n",
    "  layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a481a2-ef84-44a3-8fc1-18b08cbc7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet = mpl.colormaps[\"jet\"]\n",
    "# np.arange(10)\n",
    "# jet_colors = jet(np.arange(10))\n",
    "# jet_colors\n",
    "# jet_colors[:, :3]\n",
    "# # jet_colors = jet(np.arange(256))[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc11b8-0acd-4df8-93bb-0c977d6c747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(image_path, classif_model):\n",
    "    target_img = tf.keras.utils.load_img(image_path)\n",
    "    target_arr  = tf.keras.utils.img_to_array(target_img)\n",
    "\n",
    "    patches = get_patches(target_arr)\n",
    "    patches_predicts = classif_model.predict(resize_and_rescale(patches))\n",
    "    # patches_predicts_id = tf.math.argmax(patches_predicts, axis=-1)\n",
    "    # patches_predicts_label = class_names[patches_predicts_id]\n",
    "    patches_predicts_forrest = np.clip(patches_predicts[:, np.where(class_names == 'forest')[0]], 0, None)\n",
    "\n",
    "    patch_num_y, patch_num_x = math.floor(target_arr.shape[0]/stride_height), math.floor(target_arr.shape[1]/stride_width)\n",
    "    # classifHeatmap = create_heatmap(patches_predicts_id, (patch_num_y, patch_num_x), (patch_height, patch_width))\n",
    "    classifHeatmap = create_heatmap(patches_predicts_forrest, (patch_num_y, patch_num_x), (patch_height, patch_width))\n",
    "    classifHeatmapNorm =  np.uint8(255.*(classifHeatmap - classifHeatmap.min())/(classifHeatmap.max() - classifHeatmap.min()))\n",
    "\n",
    "    grad_cam = save_and_display_gradcam(target_arr, classifHeatmapNorm)\n",
    "    \n",
    "    return grad_cam \\\n",
    "    , classifHeatmap \\\n",
    "    , keras.utils.array_to_img( np.repeat(classifHeatmapNorm[:, :, np.newaxis], 3, axis=2)) \\\n",
    "    , target_img #keras.utils.array_to_img(target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d69b9-cb98-4506-b237-c9ebee61db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_width = math.floor(img_width*1)\n",
    "patch_height = math.floor(img_height*1)\n",
    "stride_width = patch_width\n",
    "stride_height = patch_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09eb14f-d65a-44f8-90d2-39fa1ee00416",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls -la ./../../data/MultiModalGenAI/deforestation/EldoradoNationalForest/Deforestation10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdb951-8be7-41e8-b729-dd472e680b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = './../../data/MultiModalGenAI/deforestation/EldoradoNationalForest/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e286b4-5f24-4d14-8529-bfaac070e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  8 out of 10\n",
    "# image_after_f = 'Deforestation02HR_after_07_2017'\n",
    "# image_before_f = 'Deforestation02HR_before_07_2014'\n",
    "\n",
    "# # 7 out of 10, before looks great for patches\n",
    "# image_after_f = 'Deforestation02_02HR_after_07_2017'\n",
    "# image_before_f = 'Deforestation02_02HR_before_07_2014'\n",
    "\n",
    "\n",
    "image_after_f = 'Deforestation03HR_after_09_2019'\n",
    "image_before_f = 'Deforestation03HR_before_06_2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21087770-5722-40fe-8a86-ba2bff56d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam_map_a, obj_detection_heatmap_a, deforest_index_map_a, img_a  = object_detection((images_path+image_after_f+'.jpg'), trained_model)\n",
    "grad_cam_map_a\n",
    "# deforest_index_map_a\n",
    "# img_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d304dd5-e8b9-4af7-bfd5-69fa7418e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam_map_b, obj_detection_heatmap_b, deforest_index_map_b, img_b  = object_detection((images_path+image_before_f+'.jpg'), trained_model)\n",
    "grad_cam_map_b\n",
    "# deforest_index_map_b\n",
    "# img_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cdc6b-d311-497d-a299-46bd79bb17f0",
   "metadata": {},
   "source": [
    "### Deforestation quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3177f87-7095-46f1-8565-9ae858804c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_detection_heatmap_a.shape\n",
    "obj_detection_heatmap_b.shape\n",
    "\n",
    "obj_detection_heatmap_a.max()\n",
    "obj_detection_heatmap_b.max()\n",
    "\n",
    "obj_detection_heatmap_a.min()\n",
    "obj_detection_heatmap_b.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97523dc9-2202-4d2c-a2cd-795ae0c959bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.subtract(obj_detection_heatmap_b, obj_detection_heatmap_a) #np.subtract(1.0, 4.0) -> -3.0\n",
    "\n",
    "diff.shape\n",
    "diff.max()\n",
    "diff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66434c63-af0c-4559-9a0c-e7741c2c0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_heatmap(classifHeatmap):\n",
    "    maxhp = classifHeatmap.max()\n",
    "    minhp = classifHeatmap.min()\n",
    "    return 255.*(classifHeatmap - minhp)/(maxhp - minhp)\n",
    "\n",
    "nhmb = norm_heatmap(obj_detection_heatmap_b)\n",
    "nhma = norm_heatmap(obj_detection_heatmap_a)\n",
    "nhmb.shape\n",
    "nhmb.max()\n",
    "nhmb.min()\n",
    "nhma.shape\n",
    "nhma.max()\n",
    "nhma.min()\n",
    "\n",
    "diff1 = np.subtract(nhmb, nhma)\n",
    "\n",
    "diff1.shape\n",
    "diff1.max()\n",
    "diff1.min()\n",
    "\n",
    "plt.imshow((diff1 >70) * diff1, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876230fe-548d-4a6c-81ab-88e99351ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmnorm =  np.uint8(norm_heatmap((diff1 >65) * diff1))\n",
    "grad_cam = save_and_display_gradcam(tf.keras.utils.img_to_array(img_b), hmnorm)\n",
    "grad_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ef897-f717-4bf3-9cd7-61d8d30e147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size_pixels = np.asarray([8192,4320], dtype=np.float32)\n",
    "fov_meters = np.asarray([6282, 3189], dtype=np.float32)\n",
    "\n",
    "pixel_size_meters = np.divide(fov_meters, image_size_pixels)\n",
    "pixel_size_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef4f48-05d0-4d8a-bb47-386c50fc3998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
